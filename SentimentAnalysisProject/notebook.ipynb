{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>Kaggle Competition: https://www.kaggle.com/competitions/sharif-ml-1401-pr/leaderboard</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-25T00:23:58.550732Z",
          "iopub.status.busy": "2023-06-25T00:23:58.550334Z",
          "iopub.status.idle": "2023-06-25T00:25:19.805673Z",
          "shell.execute_reply": "2023-06-25T00:25:19.804713Z",
          "shell.execute_reply.started": "2023-06-25T00:23:58.550701Z"
        },
        "id": "8fepFcMXauPc",
        "outputId": "08290f66-b5e1-4db2-c1bb-699c43109516",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4393151 sha256=bb18e10fe4ea7c16492993fe5a376da62bd5c04962292057ff5e9f98e9eadb17\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 evaluate-0.4.0 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.20.3\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install --upgrade accelerate\n",
        "!pip install accelerate -U\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import fasttext\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import numpy as np\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.utils import resample\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
        "import evaluate\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-25T00:25:19.808605Z",
          "iopub.status.busy": "2023-06-25T00:25:19.807761Z",
          "iopub.status.idle": "2023-06-25T00:25:35.410408Z",
          "shell.execute_reply": "2023-06-25T00:25:35.409113Z",
          "shell.execute_reply.started": "2023-06-25T00:25:19.808570Z"
        },
        "id": "FAm0zdagauPf",
        "outputId": "ba6dd985-2418-44ac-e2e1-8b60a42384a8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BRhlDz-JASvfEljf_XxrL-ZH4gUvOg0v\n",
            "To: /content/data-train.csv\n",
            "100% 8.48M/8.48M [00:00<00:00, 230MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!gdown --id 1BRhlDz-JASvfEljf_XxrL-ZH4gUvOg0v # data-train.csv\n",
        "# !gdown --id 1jdVascv6Y13CDTCQ04LqpcALqAWTi4a9 # total embeddings (large)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z_stskanauPh"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<font face=\"XB Zar\" size=5>\n",
        "</font>\n",
        "<font face=\"XB Zar\" size=3>\n",
        "     <br>\n",
        "در این قسمت از fasttext کمک می‌گیریم تا به یک embedding اولیه برای هر نظر برسیم.\n",
        "    با استفاده از داده‌هایی که داریم یک مدل fasttext آموزش می دهیم که برای هر توکن یک امبدینگ ۱۰۰تایی بدهد.\n",
        "    در مرحله‌ی بعد میانگین وزن دار امبدینگ های fasttext\n",
        "        توکن‌های ورودی\n",
        "    را بر اساس tfidif آن‌ها محاسبه می کنیم و به امبدینگ نهایی متن می رسیم.\n",
        "    <br>\n",
        "    در واقع به عبارت ساده‌تر بر اساس میانگین وزن‌دار که وزن‌های ما tfidf توکن‌ها می‌باشد به امبدینگ نهایی متن بر اساس fasttext می‌رسیم.\n",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YhV4sMyUGcJw"
      },
      "source": [
        "<div>We can do this feature engineering but it barely reduce accuracy of kaggle and our test accuracy will be biased so the code below is not appropriate for our task and it is schematic of a kind of feature engineering:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqpOgoC2auPv",
        "outputId": "d8d8c356-0567-488b-c7a6-ddae045f1020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2    79064\n",
            "\n",
            "3    32714\n",
            "\n",
            "1    27084\n",
            "\n",
            "4     9160\n",
            "\n",
            "0     7026\n",
            "\n",
            "Name: Sentiment, dtype: int64\n",
            "\n",
            "4    7301\n",
            "\n",
            "3    7287\n",
            "\n",
            "2    7090\n",
            "\n",
            "0    7026\n",
            "\n",
            "1    7013\n",
            "\n",
            "Name: Sentiment, dtype: int64\n",
            "\n",
            "Train set size: 22858\n",
            "\n",
            "Validation set size: 5715\n",
            "\n",
            "Test set size: 7144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-58062c9abeb3>:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "\n",
            "  df = df[~rows_to_remove2]\n",
            "\n",
            "<ipython-input-3-58062c9abeb3>:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "\n",
            "  df = df[~rows_to_remove3]\n",
            "\n",
            "<ipython-input-3-58062c9abeb3>:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "\n",
            "  df = df[~rows_to_remove4]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data-train.csv')\n",
        "\n",
        "df = df.drop_duplicates(subset='Phrase')\n",
        "topic_counts = df['Sentiment'].value_counts()\n",
        "print(topic_counts)\n",
        "\n",
        "df['phrase_length'] = df['Phrase'].apply(lambda t: len(t.split()))\n",
        "rows_to_remove1 = (df['Sentiment'] == 2) & (df['phrase_length'] < 13)\n",
        "rows_to_remove2 = (df['Sentiment'] == 3) & (df['phrase_length'] < 13)\n",
        "rows_to_remove3 = (df['Sentiment'] == 1) & (df['phrase_length'] < 13)\n",
        "rows_to_remove4 = (df['Sentiment'] == 4) & (df['phrase_length'] < 4)\n",
        "df = df[~rows_to_remove1]\n",
        "df = df[~rows_to_remove2]\n",
        "df = df[~rows_to_remove3]\n",
        "df = df[~rows_to_remove4]\n",
        "\n",
        "topic_counts = df['Sentiment'].value_counts()\n",
        "print(topic_counts)\n",
        "\n",
        "X = df['Phrase'].values\n",
        "y = df['Sentiment'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Test set size:\", len(X_test))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lrgxYdBvG3ba"
      },
      "source": [
        "<div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text, minimum_length=1, stopword_removal=True, stopwords_domain=[], lower_case=True,\n",
        "                       punctuation_removal=True):\n",
        "    \"\"\"\n",
        "    preprocess text by removing stopwords, punctuations, and converting to lowercase, and also filter based on a min length\n",
        "    for stopwords use nltk.corpus.stopwords.words('english')\n",
        "    for punctuations use string.punctuation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text: str\n",
        "        text to be preprocessed\n",
        "    minimum_length: int\n",
        "        minimum length of the token\n",
        "    stopword_removal: bool\n",
        "        whether to remove stopwords\n",
        "    stopwords_domain: list\n",
        "        list of stopwords to be removed base on domain\n",
        "    lower_case: bool\n",
        "        whether to convert to lowercase\n",
        "    punctuation_removal: bool\n",
        "        whether to remove punctuations\n",
        "    \"\"\"\n",
        "    normalized_tokens = word_tokenize(text)\n",
        "\n",
        "    if stopword_removal:\n",
        "        stopwords = [x.lower() for x in nltk.corpus.stopwords.words('english')]\n",
        "        normalized_tokens = [word for word in normalized_tokens if word.lower() not in stopwords]\n",
        "\n",
        "    if punctuation_removal:\n",
        "        normalized_tokens = [word for word in normalized_tokens if word not in string.punctuation]\n",
        "\n",
        "    if lower_case:\n",
        "        normalized_tokens = [word.lower() for word in normalized_tokens if len(word) > minimum_length]\n",
        "    else:\n",
        "        normalized_tokens = [word for word in normalized_tokens if len(word) > minimum_length]\n",
        "\n",
        "    return normalized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIZN5jDzG2pM",
        "outputId": "70bcf7f1-bdcf-4a0b-b847-15e89ec5d18d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2    79064\n",
            "3    32714\n",
            "1    27084\n",
            "4     9160\n",
            "0     7026\n",
            "Name: Sentiment, dtype: int64\n",
            "Train set size: 99230\n",
            "Validation set size: 24808\n",
            "Test set size: 31010\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data-train.csv')\n",
        "\n",
        "df = df.drop_duplicates(subset='Phrase')\n",
        "topic_counts = df['Sentiment'].value_counts()\n",
        "print(topic_counts)\n",
        "\n",
        "X = df['Phrase'].values\n",
        "y = df['Sentiment'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Test set size:\", len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7Jkn16y-auPw",
        "outputId": "f33cb8e0-462c-4c40-d11c-8b8df85133bf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-24T23:26:39.690864Z",
          "iopub.status.busy": "2023-06-24T23:26:39.690489Z",
          "iopub.status.idle": "2023-06-24T23:26:39.703781Z",
          "shell.execute_reply": "2023-06-24T23:26:39.702489Z",
          "shell.execute_reply.started": "2023-06-24T23:26:39.690827Z"
        },
        "id": "NmE24-sJauPx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "KAGGLE_RUN = 0\n",
        "COLAB_RUN = 1\n",
        "if COLAB_RUN:\n",
        "  PATH = \"\"\n",
        "else:\n",
        "    PATH = \"/kaggle/working\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zJEH0h73auPx"
      },
      "outputs": [],
      "source": [
        "class FastText:\n",
        "\n",
        "    def __init__(self, preprocessor=None, method='skipgram'):\n",
        "        self.method = method\n",
        "        self.model = None\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def train_fasttext(self, corpus_file):\n",
        "        model = fasttext.train_unsupervised(corpus_file, dim=100, model='skipgram', thread=1)\n",
        "        return model\n",
        "\n",
        "    def train(self, texts):\n",
        "        \"\"\"\n",
        "        train the fasttext model and save it into self.model\n",
        "        Parameters\n",
        "        ----------\n",
        "        texts: list of list of str\n",
        "        \"\"\"\n",
        "        with open(\"corpus.txt\", 'w') as file:\n",
        "            for doc_text in texts:\n",
        "                file.write(doc_text + '\\n')\n",
        "        self.model = self.train_fasttext(\"corpus.txt\")\n",
        "\n",
        "    def get_query_embedding(self, query, tf_idf_vectorizer):\n",
        "        \"\"\"\n",
        "        get the embedding of the query. using the tf_idf_vectorizer to get the weights of the words in the query. preprocess the query using self.preprocessor if it is not None\n",
        "        Parameters\n",
        "        ----------\n",
        "        query: str\n",
        "        tf_idf_vectorizer: TfidfVectorizer\n",
        "        Returns embedding of the query\n",
        "        \"\"\"\n",
        "        if self.preprocessor is not None:\n",
        "            query = self.preprocessor(query)\n",
        "\n",
        "        query_vector = tf_idf_vectorizer.transform([query])\n",
        "\n",
        "        query_embeddings = []\n",
        "        total_tf_idf_weight = 0\n",
        "        feature_names = tf_idf_vectorizer.get_feature_names_out()\n",
        "        for word_idx in query_vector.indices:\n",
        "            word = feature_names[word_idx]\n",
        "            tfidf_weight = query_vector[0, word_idx]\n",
        "            embedding = self.model.get_sentence_vector(word)\n",
        "            query_embeddings.append(embedding*tfidf_weight)\n",
        "            total_tf_idf_weight += tfidf_weight\n",
        "\n",
        "        if len(query_embeddings) == 0:\n",
        "           return None\n",
        "        query_embed = sum(query_embeddings) / total_tf_idf_weight\n",
        "        return query_embed\n",
        "\n",
        "    def save_FastText_model(self, path=PATH+'FastText_model.bin'):\n",
        "        self.model.save_model(path)\n",
        "\n",
        "    def load_FastText_model(self, path=PATH+\"FastText_model.bin\"):\n",
        "            self.model = fasttext.load_model(path)\n",
        "\n",
        "    def prepare(self, dataset, mode, save=False):\n",
        "        if mode == 'train':\n",
        "            self.train(dataset)\n",
        "        if mode == 'load':\n",
        "            self.load_FastText_model()\n",
        "        if save:\n",
        "            self.save_FastText_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CqGO7HTIauPy"
      },
      "outputs": [],
      "source": [
        "FastText_model = FastText()\n",
        "FastText_model.prepare(np.concatenate((X_train, X_val), axis=0), mode='train', save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R1DtQ3_auPz"
      },
      "outputs": [],
      "source": [
        "FastText_model = FastText()\n",
        "FastText_model.prepare(X, mode='load') # X is not important it just load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5wMM0TQauP0",
        "outputId": "462b6640-c760-4169-99ac-3ec538a26eb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.9571107625961304, 'Filmmaker'),\n",
              " (0.8954034447669983, 'filmmakers'),\n",
              " (0.8323990106582642, 'Filmmakers'),\n",
              " (0.8219836354255676, 'maker'),\n",
              " (0.8183867335319519, 'Widowmaker'),\n",
              " (0.8180163502693176, 'filmmaking'),\n",
              " (0.7613285779953003, 'moviemaker'),\n",
              " (0.7247695326805115, 'film'),\n",
              " (0.6816705465316772, 'Whitaker'),\n",
              " (0.6722875237464905, 'Baker')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'filmmaker'\n",
        "FastText_model.model.get_nearest_neighbors(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "flEL5KYYauP1"
      },
      "outputs": [],
      "source": [
        "class TF_IDF:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "\n",
        "    def fit_vectorizer(self, data):\n",
        "        \"\"\"\n",
        "        fit the vectorizer on the data\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: list of list of str\n",
        "        \"\"\"\n",
        "        self.vectorizer.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LsqFD5llauP1"
      },
      "outputs": [],
      "source": [
        "TF_IDF_model = TF_IDF()\n",
        "TF_IDF_model.fit_vectorizer(np.concatenate((X_train, X_val), axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUPfRfUuauP1",
        "outputId": "04e0e1a3-d548-43bf-b47f-3f1d8035a4c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.0175683  -0.05075959 -0.04655918  0.02370078  0.17468354 -0.04192305\n",
            " -0.07108051 -0.09135047 -0.03040291  0.13150744 -0.00773409  0.03174071\n",
            " -0.05552308 -0.01567124  0.01584682  0.07651385 -0.02176052 -0.0043556\n",
            " -0.04306502 -0.01256169 -0.02655373  0.04320953  0.04439824  0.02879911\n",
            " -0.03671648 -0.0081905   0.0671249  -0.125997   -0.0952822   0.00984657\n",
            "  0.02211099 -0.02201249 -0.04809056 -0.06255992 -0.1593283  -0.11429734\n",
            "  0.02620865 -0.03811052  0.01584379  0.11576615 -0.0458205   0.09378083\n",
            "  0.01835918  0.0577494   0.07291764 -0.04468565  0.01644262  0.13376845\n",
            "  0.02755518  0.07325929 -0.11079513  0.0185699   0.03593416  0.03250759\n",
            "  0.00424216 -0.02624241 -0.02313476  0.02592382 -0.04004644  0.00733271\n",
            "  0.01993223  0.07004878  0.1836217   0.07999543 -0.11743205  0.026768\n",
            " -0.00443194  0.11008079  0.01296073 -0.05213154 -0.00800286  0.07914153\n",
            " -0.02060326 -0.01564295 -0.12856068  0.12346449  0.10818127 -0.01814982\n",
            " -0.05014098 -0.01182928 -0.03022019 -0.02517278  0.03531887 -0.10271595\n",
            "  0.10618278 -0.01446165 -0.02482734  0.19284588  0.00646644 -0.0748859\n",
            "  0.08572437 -0.06097092  0.13070798 -0.13523284 -0.03284301 -0.08939946\n",
            "  0.04067443  0.14425065 -0.04720674  0.10957626]\n"
          ]
        }
      ],
      "source": [
        "text =  \"this movie is awesome\"\n",
        "TF_IDF_model.vectorizer.transform([text])\n",
        "print(FastText_model.get_query_embedding(text, TF_IDF_model.vectorizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RrXvlmEIauP2"
      },
      "outputs": [],
      "source": [
        "X_train = [FastText_model.get_query_embedding(X_train[i], TF_IDF_model.vectorizer) for i in range(len(X_train))]\n",
        "X_val = [FastText_model.get_query_embedding(X_val[i], TF_IDF_model.vectorizer) for i in range(len(X_val))]\n",
        "X_test = [FastText_model.get_query_embedding(X_test[i], TF_IDF_model.vectorizer) for i in range(len(X_test))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KRogt94PauP2"
      },
      "outputs": [],
      "source": [
        "x_train_bad_data_indices = [index for index, value in enumerate(X_train) if value is None]\n",
        "x_val_bad_data_indices = [index for index, value in enumerate(X_val) if value is None]\n",
        "x_test_bad_data_indices = [index for index, value in enumerate(X_test) if value is None]\n",
        "X_train, y_train = [X_train[i] for i in range(len(X_train)) if i not in x_train_bad_data_indices], [y_train[i] for i in range(len(X_train)) if i not in x_train_bad_data_indices]\n",
        "X_val, y_val = [X_val[i] for i in range(len(X_val)) if i not in x_val_bad_data_indices], [y_val[i] for i in range(len(y_val)) if i not in x_val_bad_data_indices]\n",
        "X_test, y_test = [X_test[i] for i in range(len(X_test)) if i not in x_test_bad_data_indices], [y_test[i] for i in range(len(y_test)) if i not in x_test_bad_data_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zjc-geLauP2",
        "outputId": "841ed444-078e-47b3-c9ac-11ee7cc58afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99126 24786 30977\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train), len(X_val), len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "v1Scg990auP2"
      },
      "outputs": [],
      "source": [
        "class PapersDataSet(Dataset):\n",
        "    def __init__(self, embeddings: list, labels: list):\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        embedding = self.embeddings[index]\n",
        "        label = self.labels[index]\n",
        "        return embedding, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5X07fJKNauP3"
      },
      "outputs": [],
      "source": [
        "train_dataset = PapersDataSet(X_train, y_train)\n",
        "val_dataset = PapersDataSet(X_val, y_val)\n",
        "test_dataset = PapersDataSet(X_test, y_test)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rb_X0FvaauP3"
      },
      "outputs": [],
      "source": [
        "class ClassifierModel(nn.Module):\n",
        "    def __init__(self, in_features=100, num_classes=5):\n",
        "        super(ClassifierModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(32, num_classes)\n",
        "        self.bn4 = nn.BatchNorm1d(num_classes)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.bn1(self.fc1(x)))\n",
        "        out = self.relu2(self.bn2(self.fc2(out)))\n",
        "        out = self.relu3(self.bn3(self.fc3(out)))\n",
        "        out = self.relu4(self.bn4(self.fc4(out)))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kopVcHNnauP4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ClassifierModel().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZVTVeTYauP4",
        "outputId": "796d3b4a-2b9e-4b32-fb9b-be24a22c2634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Z-1GykJWauP4"
      },
      "outputs": [],
      "source": [
        "def eval_epoch(model: nn.Module, criterion: nn.Module, dataloader: torch.utils.data.DataLoader, test_mode=False):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the given dataloader. used for validation and test\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "    criterion: nn.Module\n",
        "    dataloader: torch.utils.data.DataLoader\n",
        "    test_mode: bool\n",
        "        If True, the function will print 'Test' instead of 'Validation'\n",
        "    Returns\n",
        "    -------\n",
        "    eval_loss: float\n",
        "        The loss on the given dataloader\n",
        "    predicted_labels: list\n",
        "        The predicted labels\n",
        "    true_labels: list\n",
        "        The true labels\n",
        "    f1_score_micro: float\n",
        "        The f1 score on the given dataloader\n",
        "    \"\"\"\n",
        "    eval_loss = 0.0\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            eval_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predicted_labels.extend(predicted.cpu().tolist())\n",
        "            true_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    f1_score_micro = f1_score(true_labels, predicted_labels, average='micro')\n",
        "\n",
        "    return eval_loss, predicted_labels, true_labels, f1_score_micro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzpvf0peauP5",
        "outputId": "b3231d0c-4333-4a77-c9e7-113c9bc974b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 90287.7596: 100%|██████████| 3098/3098 [00:20<00:00, 151.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 finished in 21.14s\n",
            "[Epoch 1]\tTrain Loss: 0.9108\tValidation Loss: 0.9748\t F1 score micro: 0.6019123698862261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 90031.4444: 100%|██████████| 3098/3098 [00:17<00:00, 179.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 finished in 17.96s\n",
            "[Epoch 2]\tTrain Loss: 0.9083\tValidation Loss: 0.9717\t F1 score micro: 0.6028403130799646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 89845.4967: 100%|██████████| 3098/3098 [00:17<00:00, 175.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 finished in 18.53s\n",
            "[Epoch 3]\tTrain Loss: 0.9064\tValidation Loss: 0.9698\t F1 score micro: 0.6038892923424514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 89361.3878: 100%|██████████| 3098/3098 [00:17<00:00, 175.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 finished in 18.79s\n",
            "[Epoch 4]\tTrain Loss: 0.9015\tValidation Loss: 0.9717\t F1 score micro: 0.603687565561204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 89120.0997: 100%|██████████| 3098/3098 [00:17<00:00, 172.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 finished in 18.67s\n",
            "[Epoch 5]\tTrain Loss: 0.8991\tValidation Loss: 0.9719\t F1 score micro: 0.6049786169611878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 89146.4863: 100%|██████████| 3098/3098 [00:17<00:00, 177.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 finished in 18.20s\n",
            "[Epoch 6]\tTrain Loss: 0.8993\tValidation Loss: 0.9711\t F1 score micro: 0.6034858387799564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 88772.9784: 100%|██████████| 3098/3098 [00:17<00:00, 178.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 finished in 18.14s\n",
            "[Epoch 7]\tTrain Loss: 0.8956\tValidation Loss: 0.9702\t F1 score micro: 0.6057451787299282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 88401.0888: 100%|██████████| 3098/3098 [00:17<00:00, 178.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 finished in 18.13s\n",
            "[Epoch 8]\tTrain Loss: 0.8918\tValidation Loss: 0.9745\t F1 score micro: 0.607923827967401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 88357.9666: 100%|██████████| 3098/3098 [00:17<00:00, 179.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 finished in 18.10s\n",
            "[Epoch 9]\tTrain Loss: 0.8914\tValidation Loss: 0.9689\t F1 score micro: 0.6078834826111514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 88112.1615: 100%|██████████| 3098/3098 [00:17<00:00, 176.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 finished in 18.68s\n",
            "[Epoch 10]\tTrain Loss: 0.8889\tValidation Loss: 0.9719\t F1 score micro: 0.6038489469862018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 88115.8835: 100%|██████████| 3098/3098 [00:17<00:00, 172.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 finished in 18.72s\n",
            "[Epoch 11]\tTrain Loss: 0.8889\tValidation Loss: 0.9687\t F1 score micro: 0.6048172355361898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 87850.7529: 100%|██████████| 3098/3098 [00:17<00:00, 176.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 finished in 18.32s\n",
            "[Epoch 12]\tTrain Loss: 0.8863\tValidation Loss: 0.9691\t F1 score micro: 0.6064310497861696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 87624.7479: 100%|██████████| 3098/3098 [00:18<00:00, 165.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 finished in 19.50s\n",
            "[Epoch 13]\tTrain Loss: 0.8840\tValidation Loss: 0.9677\t F1 score micro: 0.608085209392399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 87550.5427: 100%|██████████| 3098/3098 [00:17<00:00, 176.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 finished in 18.25s\n",
            "[Epoch 14]\tTrain Loss: 0.8832\tValidation Loss: 0.9713\t F1 score micro: 0.6040103284111998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 87369.1651: 100%|██████████| 3098/3098 [00:17<00:00, 175.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 finished in 18.61s\n",
            "[Epoch 15]\tTrain Loss: 0.8814\tValidation Loss: 0.9653\t F1 score micro: 0.6055434519486808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 87101.1274: 100%|██████████| 3098/3098 [00:17<00:00, 175.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 finished in 18.88s\n",
            "[Epoch 16]\tTrain Loss: 0.8787\tValidation Loss: 0.9684\t F1 score micro: 0.6071572661986605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 87212.6948: 100%|██████████| 3098/3098 [00:17<00:00, 176.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 finished in 18.28s\n",
            "[Epoch 17]\tTrain Loss: 0.8798\tValidation Loss: 0.9647\t F1 score micro: 0.608246590817397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 87080.0392: 100%|██████████| 3098/3098 [00:17<00:00, 176.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 finished in 18.26s\n",
            "[Epoch 18]\tTrain Loss: 0.8785\tValidation Loss: 0.9660\t F1 score micro: 0.6096183329298798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 86776.7248: 100%|██████████| 3098/3098 [00:17<00:00, 177.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 finished in 18.24s\n",
            "[Epoch 19]\tTrain Loss: 0.8754\tValidation Loss: 0.9666\t F1 score micro: 0.607923827967401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 86647.6606: 100%|██████████| 3098/3098 [00:17<00:00, 172.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 finished in 18.68s\n",
            "[Epoch 20]\tTrain Loss: 0.8741\tValidation Loss: 0.9630\t F1 score micro: 0.611595255386105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 86428.4995: 100%|██████████| 3098/3098 [00:17<00:00, 174.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 finished in 18.67s\n",
            "[Epoch 21]\tTrain Loss: 0.8719\tValidation Loss: 0.9668\t F1 score micro: 0.6117162914548535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 86441.5293: 100%|██████████| 3098/3098 [00:17<00:00, 173.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 finished in 18.97s\n",
            "[Epoch 22]\tTrain Loss: 0.8720\tValidation Loss: 0.9662\t F1 score micro: 0.6104655854111192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 86085.2353: 100%|██████████| 3098/3098 [00:17<00:00, 176.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 finished in 18.63s\n",
            "[Epoch 23]\tTrain Loss: 0.8684\tValidation Loss: 0.9675\t F1 score micro: 0.608085209392399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 86178.3797: 100%|██████████| 3098/3098 [00:17<00:00, 173.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 finished in 18.60s\n",
            "[Epoch 24]\tTrain Loss: 0.8694\tValidation Loss: 0.9652\t F1 score micro: 0.6096990236423787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 85819.4190: 100%|██████████| 3098/3098 [00:17<00:00, 175.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 finished in 18.39s\n",
            "[Epoch 25]\tTrain Loss: 0.8658\tValidation Loss: 0.9749\t F1 score micro: 0.6063100137174211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 85971.7796: 100%|██████████| 3098/3098 [00:17<00:00, 173.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 finished in 18.58s\n",
            "[Epoch 26]\tTrain Loss: 0.8673\tValidation Loss: 0.9674\t F1 score micro: 0.6073993383361576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 86206.3905: 100%|██████████| 3098/3098 [00:17<00:00, 175.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 finished in 18.31s\n",
            "[Epoch 27]\tTrain Loss: 0.8697\tValidation Loss: 0.9719\t F1 score micro: 0.6053417251674332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 85615.4800: 100%|██████████| 3098/3098 [00:17<00:00, 179.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 finished in 18.01s\n",
            "[Epoch 28]\tTrain Loss: 0.8637\tValidation Loss: 0.9685\t F1 score micro: 0.6081659001048979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 85798.8087: 100%|██████████| 3098/3098 [00:17<00:00, 176.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 finished in 18.23s\n",
            "[Epoch 29]\tTrain Loss: 0.8656\tValidation Loss: 0.9700\t F1 score micro: 0.6061082869361737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Loss: 85436.3804: 100%|██████████| 3098/3098 [00:17<00:00, 176.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 finished in 18.25s\n",
            "[Epoch 30]\tTrain Loss: 0.8619\tValidation Loss: 0.9699\t F1 score micro: 0.6063907044299202\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Train the model for num_epochs epochs\n",
        "epoch_true and epoch_all are used to calculate the accuracy.\n",
        "epoch_true is the number of correct predictions and epoch_all is the total number of predictions in the epoch\n",
        "\"\"\"\n",
        "num_epochs = 30\n",
        "\n",
        "train_loss_arr, val_loss_arr = [], []\n",
        "f1_macro_scores_train, f1_macro_scores_val = [], []\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time()\n",
        "\n",
        "    train_loss, val_loss = 0, 0\n",
        "    epoch_all = 0\n",
        "    epoch_true = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
        "        for i, (x, label) in pbar:\n",
        "            optimizer.zero_grad()\n",
        "            inputs = x.to(device)\n",
        "            labels = label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, y_preds = torch.max(outputs, dim=1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            pbar.set_description(f'Train Loss: {train_loss:.4f}')\n",
        "\n",
        "    f1_score_micro_train = f1_score(labels.cpu(), y_preds.cpu().tolist(), average=\"micro\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    val_loss, predicted_labels, true_labels, f1_score_micro_val = eval_epoch(model, criterion, val_loader)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    train_loss_arr.append(train_loss)\n",
        "    val_loss_arr.append(val_loss)\n",
        "    f1_macro_scores_train.append(f1_score_micro_train)\n",
        "    f1_macro_scores_val.append(f1_score_micro_val)\n",
        "\n",
        "    end_time = time()\n",
        "\n",
        "    print(f'Epoch {epoch + 1} finished in {end_time - start_time:.2f}s')\n",
        "\n",
        "    print(f\"[Epoch {epoch + 1}]\\t\"\n",
        "        f\"Train Loss: {train_loss:.4f}\\t\"\n",
        "        f\"Validation Loss: {val_loss:.4f}\\t F1 score micro: {f1_score_micro_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "eyjsl5LqauP6",
        "outputId": "6ffdf3b3-2a54-4cda-c8ff-dade09ace8c7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(range(1, num_epochs + 1), train_loss_arr, label='Train Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_loss_arr, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ax6m9syaPTW",
        "outputId": "1622508e-0b79-450b-ef19-c67d25608ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6069\n",
            "\n",
            "Loss: 29809.9774\n",
            "F1-Macro: 0.6069\n",
            "F1-Micro: 0.6069\n",
            "Confusion Matrix:\n",
            "[[  339   725   244    64    12]\n",
            " [  324  2510  2216   379    32]\n",
            " [  113  1644 12352  1516    78]\n",
            " [   40   489  2561  3002   465]\n",
            " [   11    96   225   944   596]]\n",
            "Macro-Average Precision: 0.5167\n",
            "Macro-Average Recall: 0.4535\n",
            "Micro-Average Precision: 0.6069\n",
            "Micro-Average Recall: 0.6069\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "eval_loss, predicted_labels, true_labels, f1_score_macro = eval_epoch(model, criterion, test_loader, test_mode=True)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "f1_score_micro = f1_score(true_labels, predicted_labels, average='micro')\n",
        "\n",
        "confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "precision_macro = precision_score(true_labels, predicted_labels, average='macro')\n",
        "recall_macro = recall_score(true_labels, predicted_labels, average='macro')\n",
        "\n",
        "precision_micro = precision_score(true_labels, predicted_labels, average='micro')\n",
        "recall_micro = recall_score(true_labels, predicted_labels, average='micro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "print(f\"Loss: {eval_loss:.4f}\")\n",
        "print(f\"F1-Macro: {f1_score_macro:.4f}\")\n",
        "print(f\"F1-Micro: {f1_score_micro:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "print(f\"Macro-Average Precision: {precision_macro:.4f}\")\n",
        "print(f\"Macro-Average Recall: {recall_macro:.4f}\")\n",
        "print(f\"Micro-Average Precision: {precision_micro:.4f}\")\n",
        "print(f\"Micro-Average Recall: {recall_micro:.4f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ncOZYuy-OHlx"
      },
      "source": [
        "<div>accuracy with fasttext and neural network is 60% maximum, because the data is so challenging and sometime hard for experts to predict its sentiment score. but there is a better way to get a high accuracy result and it is pre-trained bert models that find a better embedding for the phrases and we will do this approach next</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-25T00:25:35.413004Z",
          "iopub.status.busy": "2023-06-25T00:25:35.412335Z",
          "iopub.status.idle": "2023-06-25T00:25:35.419338Z",
          "shell.execute_reply": "2023-06-25T00:25:35.418131Z",
          "shell.execute_reply.started": "2023-06-25T00:25:35.412966Z"
        },
        "id": "17foc7_Fa_io",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-25T00:25:35.423161Z",
          "iopub.status.busy": "2023-06-25T00:25:35.422887Z",
          "iopub.status.idle": "2023-06-25T00:25:35.663920Z",
          "shell.execute_reply": "2023-06-25T00:25:35.662887Z",
          "shell.execute_reply.started": "2023-06-25T00:25:35.423138Z"
        },
        "id": "YLk-CPkNtcrf",
        "outputId": "5b20561e-611f-4c96-ebd6-cc84917be6e0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2    79064\n",
            "3    32714\n",
            "1    27084\n",
            "4     9160\n",
            "0     7026\n",
            "Name: Sentiment, dtype: int64\n",
            "Train set size: 99230\n",
            "Validation set size: 24808\n",
            "Test set size: 31010\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data-train.csv')\n",
        "\n",
        "df = df.drop_duplicates(subset='Phrase')\n",
        "topic_counts = df['Sentiment'].value_counts()\n",
        "print(topic_counts)\n",
        "\n",
        "X = df['Phrase'].values\n",
        "y = df['Sentiment'].values\n",
        "\n",
        "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_bert, X_val_bert, y_train_bert, y_val_bert = train_test_split(X_train_bert, y_train_bert, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train set size:\", len(X_train_bert))\n",
        "print(\"Validation set size:\", len(X_val_bert))\n",
        "print(\"Test set size:\", len(X_test_bert))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-06-25T00:25:35.665676Z",
          "iopub.status.busy": "2023-06-25T00:25:35.665318Z",
          "iopub.status.idle": "2023-06-25T00:25:35.739902Z",
          "shell.execute_reply": "2023-06-25T00:25:35.738873Z",
          "shell.execute_reply.started": "2023-06-25T00:25:35.665643Z"
        },
        "id": "OFcT1QYYyw3g",
        "outputId": "252e250f-6a55-4068-c2dd-97c7618a7ed0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "5639f59f32a94b889cabd5dc3dab2c1d",
            "b7e974176d2a4f6a83ad559f8859574c",
            "6eaafb251c88483980bc7a35c6dec139",
            "c585931bf3eb4149acf5423f4b5bd365"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-06-25T00:25:35.743022Z",
          "iopub.status.busy": "2023-06-25T00:25:35.741977Z",
          "iopub.status.idle": "2023-06-25T00:26:43.115619Z",
          "shell.execute_reply": "2023-06-25T00:26:43.114574Z",
          "shell.execute_reply.started": "2023-06-25T00:25:35.742988Z"
        },
        "id": "Z2_CWoTlauP6",
        "outputId": "e43ca5f8-9913-4eaa-fa56-47fa1272cd96",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5639f59f32a94b889cabd5dc3dab2c1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7e974176d2a4f6a83ad559f8859574c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6eaafb251c88483980bc7a35c6dec139",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c585931bf3eb4149acf5423f4b5bd365",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using tokenizer on all texts. This can take a while...\n",
            "Texts padded or truncated to 71 length!\n",
            "Using tokenizer on all texts. This can take a while...\n",
            "Texts padded or truncated to 78 length!\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "model_bert = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, texts, labels):\n",
        "        self.n_examples = len(labels)\n",
        "\n",
        "        print('Using tokenizer on all texts. This can take a while...')\n",
        "        self.inputs = tokenizer(texts, add_special_tokens=True, truncation=True, padding=True, return_tensors='pt').to(device)\n",
        "\n",
        "        self.sequence_len = self.inputs['input_ids'].shape[-1]\n",
        "        print('Texts padded or truncated to %d length!' % self.sequence_len)\n",
        "\n",
        "        self.inputs.update({'labels':torch.tensor(labels).to(device)})\n",
        "\n",
        "        return\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: self.inputs[key][idx] for key in self.inputs.keys()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "\n",
        "train_dataset = CustomDataset(tokenizer, X_train_bert.tolist(), y_train_bert)\n",
        "val_dataset = CustomDataset(tokenizer, X_val_bert.tolist(), y_val_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "600248e349ad4b219319300c37bd2330"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-06-25T00:26:43.118066Z",
          "iopub.status.busy": "2023-06-25T00:26:43.117088Z",
          "iopub.status.idle": "2023-06-25T00:45:28.628420Z",
          "shell.execute_reply": "2023-06-25T00:45:28.627303Z",
          "shell.execute_reply.started": "2023-06-25T00:26:43.118030Z"
        },
        "id": "bwaOn0Q5r85z",
        "outputId": "37a67590-7ac0-42f7-a761-dc2109922886",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "600248e349ad4b219319300c37bd2330",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ········································\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20230625_002703-pnwxacf2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/agharezasharif/huggingface/runs/pnwxacf2' target=\"_blank\">winter-shape-7</a></strong> to <a href='https://wandb.ai/agharezasharif/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/agharezasharif/huggingface' target=\"_blank\">https://wandb.ai/agharezasharif/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/agharezasharif/huggingface/runs/pnwxacf2' target=\"_blank\">https://wandb.ai/agharezasharif/huggingface/runs/pnwxacf2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3101' max='3101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3101/3101 17:46, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.750100</td>\n",
              "      <td>0.739232</td>\n",
              "      <td>0.687601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3101, training_loss=0.8022068125784148, metrics={'train_runtime': 1124.4937, 'train_samples_per_second': 88.244, 'train_steps_per_second': 2.758, 'total_flos': 3620613559855260.0, 'train_loss': 0.8022068125784148, 'epoch': 1.0})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_model_without_freezing_bert_parameter\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_bert,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RjHkaSl8PmWk"
      },
      "source": [
        "<div>As you see, using bert pretrained models for embedding each phrase leads to higher accuracy.</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
