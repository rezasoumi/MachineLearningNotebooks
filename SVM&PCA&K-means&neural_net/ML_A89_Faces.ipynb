{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b07eb33c"
      },
      "source": [
        "<div>\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/6/64/Sharif_University_Logo.jpg' alt=\"SUT logo\" width=220 height=220 align=left class=\"saturate\">\n",
        "\n",
        "<br>\n",
        "<font face=\"Times New Roman\">\n",
        "<div dir=ltr align=center>\n",
        "<!-- <font color=0F5298 size=7> -->\n",
        "<font color=0F5298 size=6>\n",
        "    Introduction to Machine Learning <br> <br>\n",
        "<!-- <font color=2565AE size=5> -->\n",
        "<font size=5>\n",
        "    Computer Engineering Department <br>\n",
        "    Spring 2023 <br> <br>\n",
        "<font color=606060 size=5>\n",
        "    Homeworks 8 & 9 (Combined): Practical - Faces <br> <br>\n",
        "<font color=686880 size=4>\n",
        "    TAs: Arman Malekzadeh - Amirhossein Ramazani Bonab - Yalda Shabanzadeh\n",
        "    \n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5a79508"
      },
      "source": [
        "### Full Name : Reza Soumi\n",
        "### Student Number : 98105857\n",
        "### Colab Link: https://colab.research.google.com/drive/1KyNg_v50b9YVjsO5TxcHOwK3kSLTOJaU?usp=sharing\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, you'll be dealing with a dataset consisting of 400 faces, belonging to 40 people. Your main task is to train models capable of recognizing those faces.\n",
        "The faces are `jpg` images packed together as a zip file called `images.zip`, and the `meta.csv` determines from which person each image was taken."
      ],
      "metadata": {
        "id": "QCHy_MoXZJXG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aZE1y9wJY1Ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f90d9c1-6e08-486a-af4f-a988a669806c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-26 17:11:00--  https://www.dropbox.com/s/wrias0bjyte3rr2/images.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6022:18::a27d:4212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/wrias0bjyte3rr2/images.zip [following]\n",
            "--2023-06-26 17:11:00--  https://www.dropbox.com/s/dl/wrias0bjyte3rr2/images.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucaa0b6679aa8e74782911fc6bd9.dl.dropboxusercontent.com/cd/0/get/B-uQJfn8gf2eApZvUiGFHKfkGL7Mu8sP3a3dfQcUwWohLSDYSESPVKFIOZVpZvxyK7YlDaXAkiSXV33x23wmdfaQzDQV5FVfEbeByPBEfZnp-AewFj4L_CWFPksjOU-ayTC8eM-V5yLInfT7NgZNkw2jjTqqujOw5SYv48ePQpqF3J138ohlfSlaWQ3wOk28MwQ/file?dl=1# [following]\n",
            "--2023-06-26 17:11:01--  https://ucaa0b6679aa8e74782911fc6bd9.dl.dropboxusercontent.com/cd/0/get/B-uQJfn8gf2eApZvUiGFHKfkGL7Mu8sP3a3dfQcUwWohLSDYSESPVKFIOZVpZvxyK7YlDaXAkiSXV33x23wmdfaQzDQV5FVfEbeByPBEfZnp-AewFj4L_CWFPksjOU-ayTC8eM-V5yLInfT7NgZNkw2jjTqqujOw5SYv48ePQpqF3J138ohlfSlaWQ3wOk28MwQ/file?dl=1\n",
            "Resolving ucaa0b6679aa8e74782911fc6bd9.dl.dropboxusercontent.com (ucaa0b6679aa8e74782911fc6bd9.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to ucaa0b6679aa8e74782911fc6bd9.dl.dropboxusercontent.com (ucaa0b6679aa8e74782911fc6bd9.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 506158 (494K) [application/binary]\n",
            "Saving to: ‘images.zip’\n",
            "\n",
            "images.zip          100%[===================>] 494.29K   711KB/s    in 0.7s    \n",
            "\n",
            "2023-06-26 17:11:02 (711 KB/s) - ‘images.zip’ saved [506158/506158]\n",
            "\n",
            "--2023-06-26 17:11:02--  https://www.dropbox.com/s/vqt1v8sfmz18rcf/faces-metadata.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6022:18::a27d:4212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/vqt1v8sfmz18rcf/faces-metadata.csv [following]\n",
            "--2023-06-26 17:11:02--  https://www.dropbox.com/s/dl/vqt1v8sfmz18rcf/faces-metadata.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc790a61fdf9b4cc5514607a377f.dl.dropboxusercontent.com/cd/0/get/B-sYkab7NJrwIiiQQMZm2j1m7TyHPLOFR9_dxhIiIfdGIOFjkB36xvHuxkmUwSKv0u9VIkrcsa3Oi5x_RLJ1YvQm0Y6bkq_9jQJAEnRZHL3buLxojn2K0MKT7-HEVkuy8Hrld7ldwQlC6dpy7-ThSzw41Cy7Amq4xp6cWmzR9OLzJBlDYl-iWIbtzRrji3e5zpk/file?dl=1# [following]\n",
            "--2023-06-26 17:11:03--  https://uc790a61fdf9b4cc5514607a377f.dl.dropboxusercontent.com/cd/0/get/B-sYkab7NJrwIiiQQMZm2j1m7TyHPLOFR9_dxhIiIfdGIOFjkB36xvHuxkmUwSKv0u9VIkrcsa3Oi5x_RLJ1YvQm0Y6bkq_9jQJAEnRZHL3buLxojn2K0MKT7-HEVkuy8Hrld7ldwQlC6dpy7-ThSzw41Cy7Amq4xp6cWmzR9OLzJBlDYl-iWIbtzRrji3e5zpk/file?dl=1\n",
            "Resolving uc790a61fdf9b4cc5514607a377f.dl.dropboxusercontent.com (uc790a61fdf9b4cc5514607a377f.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uc790a61fdf9b4cc5514607a377f.dl.dropboxusercontent.com (uc790a61fdf9b4cc5514607a377f.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5891 (5.8K) [application/binary]\n",
            "Saving to: ‘meta.csv’\n",
            "\n",
            "meta.csv            100%[===================>]   5.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-26 17:11:03 (683 MB/s) - ‘meta.csv’ saved [5891/5891]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O images.zip https://www.dropbox.com/s/wrias0bjyte3rr2/images.zip?dl=1\n",
        "!wget -O meta.csv https://www.dropbox.com/s/vqt1v8sfmz18rcf/faces-metadata.csv?dl=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use the following packages\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from typing import List\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "6_7895lFnun2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sec 1: Data Preparation"
      ],
      "metadata": {
        "id": "rOuCpoXVxYAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all images as a numpy array (called `x`) and the metadata as a dataframe **(P1-1: 25 points)**"
      ],
      "metadata": {
        "id": "D67J4M0lnD62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('images.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('images')\n",
        "PATH = \"images/content/img-data/\"\n",
        "\n",
        "metadata = pd.read_csv('meta.csv')\n",
        "\n",
        "image_paths = metadata['path'].tolist()\n",
        "x = np.array([np.array(Image.open(PATH+path)) for path in image_paths])"
      ],
      "metadata": {
        "id": "J1a0H7bPQRZA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten and normalize the images **(P1-2: 10 points)**\n",
        "\n",
        "Note: For this part, normalization only means dividing by 255."
      ],
      "metadata": {
        "id": "Bllz0xnSn6Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_flat = x.reshape(x.shape[0], -1)\n",
        "\n",
        "x_normalized = x_flat / 255.0"
      ],
      "metadata": {
        "id": "mcAT92tIvMk_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode the labels using `LabelEncoder` and save the result as a numpy array called `y` **(P1-3: 5 points)**"
      ],
      "metadata": {
        "id": "ZyXQqbNLuAJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(metadata['label'])"
      ],
      "metadata": {
        "id": "rz1_cg3ipHLE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into training (80%), validation (10%), and testing (10%) parts. **(P1-4: 10 points)**\n",
        "\n",
        "Note: The split procedure should maintain the class balance. This is sometimes called \"[stratified sampling](https://en.wikipedia.org/wiki/Stratified_sampling)\"."
      ],
      "metadata": {
        "id": "o4yGbT6HuDks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_normalized, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, stratify=y_test, random_state=42)"
      ],
      "metadata": {
        "id": "MtOoeS0ewOye"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sec 2: SVM"
      ],
      "metadata": {
        "id": "G8YV5obFxgmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subsec 2.1."
      ],
      "metadata": {
        "id": "ZhlriGrP1T9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a SVM using `sklearn`. Note that the hyperparameter tuning should be done using the \"validation\" set. **(P2-1-1: 20 points)**"
      ],
      "metadata": {
        "id": "5n0SLDtE0vih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC()\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': [0.1, 1, 'scale']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "best_params, best_score = 0, 0\n",
        "for i in range(len(grid_search.cv_results_['params'])):\n",
        "    params = grid_search.cv_results_['params'][i]\n",
        "\n",
        "    svm = SVC(**params)\n",
        "    svm.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = svm.predict(x_val)\n",
        "\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    if f1 > best_score:\n",
        "        best_score = f1\n",
        "        best_params = params\n",
        "\n",
        "print(best_params)\n",
        "svm = SVC(**best_params)\n",
        "svm.fit(x_train, y_train)\n",
        "\n",
        "accuracy = svm.score(x_val, y_val)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "LBA5UHB9_4Sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefbcefb-0cbe-422a-8510-baaca96f6b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
            "0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report the accuracy and F1-score of the classifier on the testing set **(P2-1-2: 10 points)**"
      ],
      "metadata": {
        "id": "mP97Fgtq03I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_search.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "9hAz00vB1S8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae48d38-79c3-4014-c707-bef3dcedf138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.975\n",
            "F1-score: 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subsec 2.2."
      ],
      "metadata": {
        "id": "JsaU0aq71ctB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a SVM from scratch using the following class **(P2-2-1: 40 points)**\n",
        "\n",
        "Note: For this part, you are not required to use the validation set for hyperparameter tuning. However, you might get better results if you do that."
      ],
      "metadata": {
        "id": "N-xU9teJ1gwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cvxopt import matrix, solvers\n",
        "\n",
        "class SVM:\n",
        "    def __init__(self):\n",
        "        self.support_vectors = None\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.num_classes = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit the SVM model to dataset X in one-vs-one manner.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where `n_samples` is the number of samples\n",
        "            and `n_features` is the number of features.\n",
        "\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Training labels, where `n_samples` is the number of samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns the instance itself.\n",
        "        \"\"\"\n",
        "\n",
        "        num_samples, num_features = X.shape\n",
        "        self.num_classes = len(np.unique(y))\n",
        "        self.support_vectors = []\n",
        "        self.weights = []\n",
        "        self.bias = []\n",
        "\n",
        "        for class_a in range(self.num_classes):\n",
        "            for class_b in range(class_a + 1, self.num_classes):\n",
        "                mask = np.logical_or(y == class_a, y == class_b)\n",
        "                X_ab = X[mask]\n",
        "                y_ab = y[mask]\n",
        "                y_ab = np.where(y_ab == class_a, -1, 1)  # Label class_a as -1 and class_b as 1\n",
        "\n",
        "                alpha = self._solve_qp(X_ab, y_ab)\n",
        "\n",
        "                support_vector_indices = alpha > 0\n",
        "                self.support_vectors.append(X_ab[support_vector_indices])\n",
        "                self.weights.append(np.sum(alpha[:, np.newaxis] * (y_ab[:, np.newaxis] * X_ab), axis=0))\n",
        "\n",
        "                bias = np.mean(y_ab[support_vector_indices] - np.dot(X_ab[support_vector_indices], self.weights[-1]))\n",
        "                self.bias.append(bias)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Fit the model with X and apply the dimensionality reduction on X. SVM is one-vs-one manner and there is\n",
        "        self.support_vectors = None\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        from training phase\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where `n_samples` is the number of samples\n",
        "            and `n_features` is the number of features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y_pred : ndarray of shape (n_samples)\n",
        "            Your predictions for the class of each sample\n",
        "        \"\"\"\n",
        "\n",
        "        num_samples = X.shape[0]\n",
        "        num_classes = self.num_classes\n",
        "\n",
        "        y_pred = []\n",
        "        for x in X:\n",
        "            a = 0\n",
        "            x_score = [0] * num_classes\n",
        "            for class_a in range(self.num_classes):\n",
        "                for class_b in range(class_a + 1, self.num_classes):\n",
        "                    score = np.dot(x, self.weights[a]) + self.bias[a]\n",
        "                    if score > 0:\n",
        "                        x_score[class_b] += 1\n",
        "                    else:\n",
        "                        x_score[class_a] += 1\n",
        "                    a += 1\n",
        "            y_pred.append(np.argmax(x_score))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def _solve_qp(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        P = matrix(np.dot(X, X.T) * np.outer(y, y))\n",
        "        q = matrix(-np.ones(num_samples))\n",
        "        G = matrix(-np.eye(num_samples))\n",
        "        h = matrix(np.zeros(num_samples))\n",
        "        A = matrix(y.reshape(1, -1), tc='d')\n",
        "        b = matrix(0.0)\n",
        "\n",
        "        solvers.options['show_progress'] = False\n",
        "        solution = solvers.qp(P, q, G, h, A, b)\n",
        "        alpha = np.array(solution['x']).flatten()\n",
        "        return alpha\n",
        "\n",
        "svm_model = SVM()\n",
        "\n",
        "svm_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "rxOy4Ino1fHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671831ce-0443-4ea0-a9e9-ac102ed96119"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SVM at 0x7f6b14388d90>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report the accuracy and F1-score of the classifier on the testing set **(P2-2-2: 10 points)**"
      ],
      "metadata": {
        "id": "j193U_4l2d6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "y_pred = svm_model.transform(x_test)\n",
        "print(y_pred)\n",
        "print(y_test)\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "f1_micro = f1_score(y_pred, y_test, average='micro')\n",
        "f1_macro = f1_score(y_pred, y_test, average='macro')\n",
        "print(\"\\nAccuracy on test set: {:.2f}\".format(accuracy))\n",
        "print(\"F1_micro on test set: {:.2f}\".format(f1_micro))\n",
        "print(\"F1_macro on test set: {:.2f}\".format(f1_macro))"
      ],
      "metadata": {
        "id": "gC9xLewr2euh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d242d68-b7cd-4402-f021-44fcf27d5884"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29, 22, 12, 16, 4, 10, 9, 26, 5, 12, 37, 18, 23, 30, 0, 28, 35, 21, 7, 11, 34, 36, 19, 1, 33, 32, 25, 31, 13, 38, 24, 3, 17, 8, 20, 6, 2, 14, 15, 27]\n",
            "[29 22 30 16  4 10  9 26  5 12 37 18 23 30  0 28 35 21  7 11 34 36 19  1\n",
            " 33 32 25 31 13 38 24  3 17  8 20  6  2 14 15 27]\n",
            "\n",
            "Accuracy on test set: 0.97\n",
            "F1_micro on test set: 0.97\n",
            "F1_macro on test set: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sec 3: PCA"
      ],
      "metadata": {
        "id": "rRmd_iUI1mn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch all images taken from `jones`, `taylor`, `anderson` and `wilson` (use the `labelencoder` object). Perform PCA from scratch using the following `class` to reduce the dimension of those images to 3. Save the results as a `numpy` array of shape `(40, 3)`. **(P3-1: 30 points)**"
      ],
      "metadata": {
        "id": "rjYFWT1-2jNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULX2SYCXRB49",
        "outputId": "1fd5c89e-8344-41c5-9211-c7a4f2b570b9"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['jones', 'taylor', 'anderson', 'wilson']\n",
        "target_indices = np.where(np.isin(y, label_encoder.transform(target_names)))\n",
        "x_target = x_flat[target_indices]\n",
        "y_target = y[target_indices]"
      ],
      "metadata": {
        "id": "QDjqK4H69mSc"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFyjMoo-RUoI",
        "outputId": "ada84b4c-9735-42df-ff0b-5dd0dc19c90b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsOf5NENVI48",
        "outputId": "7dad8412-b7f0-4ff8-b72f-7d7026495fc8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PCA:\n",
        "    def __init__(self, n_components):\n",
        "        self.n_components = n_components\n",
        "        self.components_ = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"Fit the model with X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where `n_samples` is the number of samples\n",
        "            and `n_features` is the number of features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns the instance itself.\n",
        "        \"\"\"\n",
        "        X_centered = X - np.mean(X, axis=0)\n",
        "\n",
        "        cov_matrix = np.cov(X_centered, rowvar=False)\n",
        "\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "        sorted_eigenvalues = eigenvalues[sorted_indices]\n",
        "        sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "        self.components_ = sorted_eigenvectors[:, :self.n_components]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Fit the model with X and apply the dimensionality reduction on X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where `n_samples` is the number of samples\n",
        "            and `n_features` is the number of features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X_new : ndarray of shape (n_samples, n_components)\n",
        "            Transformed values.\n",
        "        \"\"\"\n",
        "        assert self.components_ is not None\n",
        "\n",
        "        X_centered = X - np.mean(X, axis=0)\n",
        "\n",
        "        X_transformed = np.dot(X_centered, self.components_)\n",
        "\n",
        "        return X_transformed"
      ],
      "metadata": {
        "id": "nz8BZ31S2h7d"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(3)\n",
        "pca.fit(x_target)\n",
        "x_pca = pca.transform(x_target)"
      ],
      "metadata": {
        "id": "aC32bpqpgtc-"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_pca.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ogH90cUFOs",
        "outputId": "e716c61c-5c3a-4a16-eb0c-b62028e67ca5"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `plotly` to plot these 3D samples. You should use their labels as the determiner of their color. **(P3-2: 10 points)**"
      ],
      "metadata": {
        "id": "XpkXp5u83EPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "By running this cell, pca_plot.html will create. It is attached with this notebook.\n",
        "</div>"
      ],
      "metadata": {
        "id": "fQ2Bc7LTbwsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "x_pca_real = np.real(x_pca)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'PC1': x_pca_real[:, 0],\n",
        "    'PC2': x_pca_real[:, 1],\n",
        "    'PC3': x_pca_real[:, 2],\n",
        "    'Label': label_encoder.inverse_transform(y_target)\n",
        "})\n",
        "\n",
        "df['Color'] = label_encoder.transform(df['Label'])\n",
        "\n",
        "colors = ['blue', 'red', 'green', 'yellow']\n",
        "colormap = {label: color for label, color in zip(df['Label'].unique(), colors)}\n",
        "\n",
        "fig = px.scatter_3d(df, x='PC1', y='PC2', z='PC3', color='Color', color_discrete_map=colormap)\n",
        "\n",
        "fig.update_layout(scene=dict(xaxis_title='Principal Component 1', yaxis_title='Principal Component 2', zaxis_title='Principal Component 3'))\n",
        "\n",
        "fig.write_html('pca_plot.html')"
      ],
      "metadata": {
        "id": "upHyFtFL2CBE"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sec 4: K-Means"
      ],
      "metadata": {
        "id": "05G8GNkq3ySI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using K-means, we want to perform clustering on the 3D samples. Consider 4 clusters. After running the K-means algorithm on the data, determine to which cluster each sample belongs. Then, use `plotly` to plot the 3D samples colored with respect to their clusters. **(P4-1: 15 points)**"
      ],
      "metadata": {
        "id": "99sy2kUTNKAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_2d_tsne(vecs : List):\n",
        "\n",
        "    vecs = np.array(vecs)\n",
        "    tsne = TSNE(n_components=2)\n",
        "\n",
        "    vecs_2d = tsne.fit_transform(vecs)\n",
        "\n",
        "    return vecs_2d\n",
        "\n",
        "images_2d = np.array(convert_to_2d_tsne(x_normalized))"
      ],
      "metadata": {
        "id": "IAFczpg12D5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_docs(vecs_2d: List, labels : List):\n",
        "\n",
        "    unique_labels = np.unique(labels)\n",
        "\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        vecs_2d_cluster = vecs_2d[labels == label]\n",
        "        ax.scatter(vecs_2d_cluster[:, 0], vecs_2d_cluster[:, 1], c=colors[i], label=label)\n",
        "\n",
        "    ax.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LCKPkFHT3cfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KMeans:\n",
        "    \"\"\"\n",
        "    Fits it on data, then uses predict to get cluster labels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.centroids = None\n",
        "        self.labels = None\n",
        "        self.true_labels = None\n",
        "\n",
        "    def fit(self, x, y, n_clusters):\n",
        "        \"\"\"Fits the training data\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : array-like, shape = [n_samples, n_features]\n",
        "            Training samples\n",
        "        y : array-like, shape = [n_samples, n_target_values]\n",
        "            Target values\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "        self.true_labels = y\n",
        "\n",
        "        x = np.array(x)\n",
        "        self.centroids = x[np.random.choice(x.shape[0], n_clusters, replace=False)]\n",
        "\n",
        "        for i in range(100):\n",
        "            distances = np.sqrt(((x - self.centroids[:, np.newaxis])**2).sum(axis=2))\n",
        "            self.labels = np.argmin(distances, axis=0)\n",
        "\n",
        "            for j in range(n_clusters):\n",
        "                self.centroids[j] = x[self.labels == j].mean(axis=0)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\" Predicts the cluster label\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : array-like, shape = [n_samples, n_features]\n",
        "            Test samples\n",
        "        Returns\n",
        "        -------\n",
        "        Predicted cluster label\n",
        "        \"\"\"\n",
        "\n",
        "        distances = np.sqrt(((x - self.centroids[:, np.newaxis])**2).sum(axis=2))\n",
        "        labels = np.argmin(distances, axis=0)\n",
        "\n",
        "        return labels"
      ],
      "metadata": {
        "id": "SzNxiAjkOYYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_means = KMeans()\n",
        "k_means.fit(x_normalized, y, n_clusters=4)\n",
        "cluster_labels = k_means.labels\n",
        "plot_docs(images_2d, cluster_labels)"
      ],
      "metadata": {
        "id": "spAwNfSITeT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "5c3418a0-db1e-4f5b-8d4f-b6f43f1e5de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-234b8003d354>:11: UserWarning:\n",
            "\n",
            "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure the quality of the clustering using \"silhoutte score\" **(P4-2: 5 points)**\n",
        "\n",
        "Note: You can use `sklearn` or other packages to calculate the score."
      ],
      "metadata": {
        "id": "8J5FN-HIOOqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_score = silhouette_score(images_2d, cluster_labels)\n",
        "print(silhouette_score)"
      ],
      "metadata": {
        "id": "1zdNLJ_9OYxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0de66ed-5cc0-469f-d61c-d4d926997b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.073922046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the result of the clustering with the original labels. To be more precise, in this part, you should clearly answer the following questions with details:<br>\n",
        "\n",
        "- Does each cluster represent a true label?\n",
        "- What is your conclusion?\n",
        "\n",
        "**(P4-3: 10 points)**"
      ],
      "metadata": {
        "id": "znohK44UQ5s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = k_means.labels\n",
        "true_labels = k_means.true_labels\n",
        "\n",
        "cluster_majority_labels = {}\n",
        "\n",
        "for cluster in np.unique(predicted_labels):\n",
        "    cluster_samples = true_labels[predicted_labels == cluster]\n",
        "    majority_label = np.argmax(np.bincount(cluster_samples))\n",
        "    cluster_majority_labels[cluster] = majority_label\n",
        "\n",
        "for cluster, majority_label in cluster_majority_labels.items():\n",
        "    print(f\"Cluster {cluster}: Majority Label - {majority_label}/{len(unique_labels)}\")\n",
        "    cluster_samples = true_labels[predicted_labels == cluster]\n",
        "    unique_labels, label_counts = np.unique(cluster_samples, return_counts=True)\n",
        "    print(f\"   True Labels: {unique_labels}\")\n",
        "    print(f\"   Label Counts: {label_counts}\\n\")"
      ],
      "metadata": {
        "id": "DDfOcVckRboQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b007d54-4de4-442e-8c33-1abf2fc627a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0: Majority Label - 11/25\n",
            "   True Labels: [ 1  3  5  6  9 11 17 20 22 24 26 34 36 37 38]\n",
            "   Label Counts: [ 3  9  8  6  2 10  5  2  1  1  1  2  1  2  5]\n",
            "\n",
            "Cluster 1: Majority Label - 4/15\n",
            "   True Labels: [ 0  1  2  3  4  5  6  7  8  9 10 12 15 17 18 19 22 23 24 26 28 29 30 32\n",
            " 33 34 35 36 37 38]\n",
            "   Label Counts: [ 1  6  5  1 10  1  3  7 10  6 10  3  9  2  4 10  9  9  5  9  3  8  6  4\n",
            " 10  3  2  4  5  4]\n",
            "\n",
            "Cluster 2: Majority Label - 13/30\n",
            "   True Labels: [12 13 14 16 18 21 25 27 28 30 31 35]\n",
            "   Label Counts: [ 4 10 10  6  1  7 10 10  3  5 10  2]\n",
            "\n",
            "Cluster 3: Majority Label - 0/12\n",
            "   True Labels: [ 0  1  2  5  6  7  9 12 15 16 17 18 20 21 23 24 28 29 30 32 34 35 36 37\n",
            " 38]\n",
            "   Label Counts: [9 1 5 1 1 3 2 3 1 4 3 5 8 3 1 4 4 2 9 6 5 6 5 3 1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "Does each cluster represent a true label?\n",
        "\n",
        "Ideally, in a perfect clustering scenario, each cluster would represent a distinct true label. However, in reality, it is not guaranteed that each cluster will align perfectly with the true labels. The quality of the clustering depends on the inherent structure of the data and the effectiveness of the algorithm.\n",
        "\n",
        "What is your conclusion?\n",
        "\n",
        "The accuracy score obtained from comparing the clustering results with the original labels provides a measure of how well the clusters align with the true labels. A higher accuracy score indicates a better alignment. If the accuracy score is close to 1, it suggests that the clusters represent the true labels well. On the other hand, if the accuracy score is low, it indicates that the clustering did not capture the true label structure effectively.\n",
        "</div>"
      ],
      "metadata": {
        "id": "TXTtljTGctzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sec 5: Neural Net (Optional with Bonus Points)"
      ],
      "metadata": {
        "id": "l2rNsjun2MYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape the images so that they become of shape `64x64` **(P5-1: 5 points)**"
      ],
      "metadata": {
        "id": "kHrNE4gp2-AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1, 64, 64)\n",
        "x_val = x_val.reshape(-1, 64, 64)\n",
        "x_test = x_test.reshape(-1, 64, 64)"
      ],
      "metadata": {
        "id": "OaCDrh9g3Sbd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQfCpbhIuFEd",
        "outputId": "eb5f803d-e13c-4f7a-8024-96216594c613"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use different types of augmentation techniques (such as Random Flipping, Random Rotation, etc.) to increase the size of the training dataset. **(P5-2: 10 points)**"
      ],
      "metadata": {
        "id": "PC0kN0MPOcak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "x_train = x_train.reshape(-1, 64, 64, 1)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "augmented_data = datagen.flow(x_train, y_train, batch_size=32)"
      ],
      "metadata": {
        "id": "QbUC-Y5mP4Xd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_augmented_images = len(augmented_data) * augmented_data.batch_size\n",
        "print(\"Total number of augmented images:\", total_num_augmented_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q6lWLQyveAF",
        "outputId": "3d617283-836b-4a31-d8f2-dcb7c58dd3bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of augmented images: 320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(augmented_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXEfuGp9vUZz",
        "outputId": "852682eb-4379-4207-cb84-68529321ad4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.preprocessing.image.NumpyArrayIterator"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the augmented training set, train a neural network consisting of 2D convolutional layers. The exact architecture of the network is arbitrary. However, the last layer should have the \"softmax\" function as its activation. Also, using \"max pooling\" layers after convolutional ones is advised.\n",
        "\n",
        "Note: Don't get frustrated if your network does not appear to be a good one. Give it some time to be trained. For instance, you might need to train it for 100 epochs. Make sure to try that out before quitting!\n",
        "\n",
        "**(P5-3: 20 points)**"
      ],
      "metadata": {
        "id": "uXVXHAIgOp_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(40, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(augmented_data, epochs=150, validation_data=(x_val, y_val))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "WgODL6JyPdY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e63d48-0e3b-423b-bc0e-35ebe794c4cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "10/10 [==============================] - 3s 217ms/step - loss: 3.7305 - accuracy: 0.0125 - val_loss: 3.6874 - val_accuracy: 0.0250\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 3.6879 - accuracy: 0.0156 - val_loss: 3.6851 - val_accuracy: 0.0250\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 3s 303ms/step - loss: 3.6862 - accuracy: 0.0437 - val_loss: 3.6787 - val_accuracy: 0.0500\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 3.6815 - accuracy: 0.0500 - val_loss: 3.6714 - val_accuracy: 0.0500\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 3.6783 - accuracy: 0.0500 - val_loss: 3.6617 - val_accuracy: 0.0500\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 3.6693 - accuracy: 0.0500 - val_loss: 3.6510 - val_accuracy: 0.0500\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 3s 258ms/step - loss: 3.6536 - accuracy: 0.0500 - val_loss: 3.6364 - val_accuracy: 0.0500\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 3.6468 - accuracy: 0.0500 - val_loss: 3.6210 - val_accuracy: 0.0500\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 3.6149 - accuracy: 0.0500 - val_loss: 3.5763 - val_accuracy: 0.0500\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 3.6153 - accuracy: 0.0594 - val_loss: 3.5693 - val_accuracy: 0.0750\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 3.5407 - accuracy: 0.0625 - val_loss: 3.4490 - val_accuracy: 0.0750\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 3s 274ms/step - loss: 3.4174 - accuracy: 0.1125 - val_loss: 3.2528 - val_accuracy: 0.2000\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 3.3703 - accuracy: 0.0781 - val_loss: 3.2803 - val_accuracy: 0.1250\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 3.2030 - accuracy: 0.1406 - val_loss: 2.9614 - val_accuracy: 0.1250\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 3.0471 - accuracy: 0.1469 - val_loss: 2.7665 - val_accuracy: 0.2750\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 3s 332ms/step - loss: 2.9014 - accuracy: 0.2188 - val_loss: 2.6904 - val_accuracy: 0.3500\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 2.8183 - accuracy: 0.2125 - val_loss: 2.5512 - val_accuracy: 0.3250\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 2.7325 - accuracy: 0.2500 - val_loss: 2.4655 - val_accuracy: 0.3750\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 2.7332 - accuracy: 0.2188 - val_loss: 2.3875 - val_accuracy: 0.3500\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 2.5131 - accuracy: 0.2875 - val_loss: 2.2836 - val_accuracy: 0.3500\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 2s 231ms/step - loss: 2.5310 - accuracy: 0.2937 - val_loss: 2.2443 - val_accuracy: 0.3750\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 3s 256ms/step - loss: 2.3726 - accuracy: 0.3500 - val_loss: 2.0683 - val_accuracy: 0.3750\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 2.3730 - accuracy: 0.2781 - val_loss: 1.9251 - val_accuracy: 0.5250\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 2.2571 - accuracy: 0.3219 - val_loss: 2.3256 - val_accuracy: 0.4000\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 2.3010 - accuracy: 0.3156 - val_loss: 1.7931 - val_accuracy: 0.5500\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 2.1527 - accuracy: 0.3875 - val_loss: 1.8174 - val_accuracy: 0.5000\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 2.0793 - accuracy: 0.4031 - val_loss: 1.6165 - val_accuracy: 0.6250\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 3s 240ms/step - loss: 2.0567 - accuracy: 0.3625 - val_loss: 1.7036 - val_accuracy: 0.5750\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 2.0046 - accuracy: 0.4000 - val_loss: 1.6165 - val_accuracy: 0.5750\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 1.9702 - accuracy: 0.4437 - val_loss: 1.6224 - val_accuracy: 0.6000\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 1.8784 - accuracy: 0.4187 - val_loss: 1.5158 - val_accuracy: 0.6250\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 1.8171 - accuracy: 0.4375 - val_loss: 1.5121 - val_accuracy: 0.6750\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 3s 291ms/step - loss: 1.9637 - accuracy: 0.4281 - val_loss: 1.5526 - val_accuracy: 0.5500\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 1.8423 - accuracy: 0.4406 - val_loss: 1.4193 - val_accuracy: 0.6500\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 1.8807 - accuracy: 0.4594 - val_loss: 1.4427 - val_accuracy: 0.6750\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 1.7991 - accuracy: 0.4844 - val_loss: 1.3764 - val_accuracy: 0.6250\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 1.7341 - accuracy: 0.4750 - val_loss: 1.2932 - val_accuracy: 0.7000\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 1.8069 - accuracy: 0.4969 - val_loss: 1.3605 - val_accuracy: 0.5750\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 1.7898 - accuracy: 0.4688 - val_loss: 1.2902 - val_accuracy: 0.6500\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 1.7221 - accuracy: 0.5000 - val_loss: 1.2003 - val_accuracy: 0.6250\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 2s 243ms/step - loss: 1.6126 - accuracy: 0.5312 - val_loss: 1.2640 - val_accuracy: 0.6500\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 1.6352 - accuracy: 0.5156 - val_loss: 1.2166 - val_accuracy: 0.7750\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 1.6845 - accuracy: 0.4844 - val_loss: 1.1385 - val_accuracy: 0.7000\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 1.5680 - accuracy: 0.5063 - val_loss: 1.2614 - val_accuracy: 0.7250\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 1.5801 - accuracy: 0.5156 - val_loss: 1.2449 - val_accuracy: 0.7000\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 1.6528 - accuracy: 0.5094 - val_loss: 1.0753 - val_accuracy: 0.7250\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 1.4164 - accuracy: 0.5750 - val_loss: 0.9273 - val_accuracy: 0.7500\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 1.4163 - accuracy: 0.5437 - val_loss: 0.9599 - val_accuracy: 0.7750\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 3s 350ms/step - loss: 1.4545 - accuracy: 0.5719 - val_loss: 0.8692 - val_accuracy: 0.8000\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 1.4802 - accuracy: 0.5594 - val_loss: 1.0352 - val_accuracy: 0.7750\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 1.4341 - accuracy: 0.5875 - val_loss: 0.8015 - val_accuracy: 0.8500\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 1.4212 - accuracy: 0.5719 - val_loss: 0.9733 - val_accuracy: 0.7250\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 2s 232ms/step - loss: 1.3289 - accuracy: 0.5969 - val_loss: 0.8205 - val_accuracy: 0.7500\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 3s 249ms/step - loss: 1.3664 - accuracy: 0.5719 - val_loss: 0.9532 - val_accuracy: 0.7750\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 1.4581 - accuracy: 0.5531 - val_loss: 0.8178 - val_accuracy: 0.8500\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 1.3575 - accuracy: 0.6000 - val_loss: 0.7394 - val_accuracy: 0.8250\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 1.3576 - accuracy: 0.6031 - val_loss: 0.8714 - val_accuracy: 0.7500\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 1.3790 - accuracy: 0.5906 - val_loss: 0.8244 - val_accuracy: 0.8500\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 3s 269ms/step - loss: 1.2763 - accuracy: 0.6094 - val_loss: 0.7498 - val_accuracy: 0.7500\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 3s 241ms/step - loss: 1.3102 - accuracy: 0.6000 - val_loss: 0.8944 - val_accuracy: 0.7500\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 1.3051 - accuracy: 0.6094 - val_loss: 0.7710 - val_accuracy: 0.7500\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 1.2010 - accuracy: 0.6344 - val_loss: 0.6949 - val_accuracy: 0.8000\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 1.0858 - accuracy: 0.6938 - val_loss: 0.6612 - val_accuracy: 0.7750\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 2s 227ms/step - loss: 1.2417 - accuracy: 0.6281 - val_loss: 0.7240 - val_accuracy: 0.8000\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 3s 296ms/step - loss: 1.1642 - accuracy: 0.6656 - val_loss: 0.7336 - val_accuracy: 0.8000\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 1.2035 - accuracy: 0.6250 - val_loss: 0.7983 - val_accuracy: 0.7500\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 1.2370 - accuracy: 0.5750 - val_loss: 0.8492 - val_accuracy: 0.7500\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 1.2247 - accuracy: 0.6156 - val_loss: 0.7033 - val_accuracy: 0.8000\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 3s 331ms/step - loss: 1.0670 - accuracy: 0.6781 - val_loss: 0.7087 - val_accuracy: 0.7750\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 1.0920 - accuracy: 0.6719 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 1.0399 - accuracy: 0.6750 - val_loss: 0.5199 - val_accuracy: 0.9000\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 1.0597 - accuracy: 0.7063 - val_loss: 0.6098 - val_accuracy: 0.8250\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 3s 299ms/step - loss: 1.0997 - accuracy: 0.6625 - val_loss: 0.5559 - val_accuracy: 0.8500\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 2s 225ms/step - loss: 1.0698 - accuracy: 0.6781 - val_loss: 0.5536 - val_accuracy: 0.8750\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 1.0378 - accuracy: 0.6844 - val_loss: 0.7166 - val_accuracy: 0.7750\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 1.1710 - accuracy: 0.6500 - val_loss: 0.6756 - val_accuracy: 0.8500\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.9996 - accuracy: 0.6844 - val_loss: 0.6685 - val_accuracy: 0.7750\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 1.0169 - accuracy: 0.6625 - val_loss: 0.6112 - val_accuracy: 0.8500\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 3s 262ms/step - loss: 0.9810 - accuracy: 0.6969 - val_loss: 0.5866 - val_accuracy: 0.8500\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 1.1210 - accuracy: 0.6531 - val_loss: 0.6141 - val_accuracy: 0.8500\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 1.0208 - accuracy: 0.7031 - val_loss: 0.5805 - val_accuracy: 0.8250\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 1.0302 - accuracy: 0.7031 - val_loss: 0.5412 - val_accuracy: 0.8250\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 3s 309ms/step - loss: 0.9850 - accuracy: 0.6906 - val_loss: 0.5708 - val_accuracy: 0.8750\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.8839 - accuracy: 0.7594 - val_loss: 0.4444 - val_accuracy: 0.9000\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.8777 - accuracy: 0.7125 - val_loss: 0.5469 - val_accuracy: 0.8750\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.9289 - accuracy: 0.7188 - val_loss: 0.8141 - val_accuracy: 0.6500\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 3s 273ms/step - loss: 0.8997 - accuracy: 0.7094 - val_loss: 1.0764 - val_accuracy: 0.6500\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.9395 - accuracy: 0.6969 - val_loss: 0.8124 - val_accuracy: 0.6750\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.8223 - accuracy: 0.7469 - val_loss: 0.6333 - val_accuracy: 0.8250\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.9210 - accuracy: 0.7156 - val_loss: 0.5895 - val_accuracy: 0.8250\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.8261 - accuracy: 0.7250 - val_loss: 0.5125 - val_accuracy: 0.8750\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 3s 300ms/step - loss: 0.7589 - accuracy: 0.7594 - val_loss: 0.4722 - val_accuracy: 0.8500\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.7739 - accuracy: 0.7844 - val_loss: 0.5189 - val_accuracy: 0.8750\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.8171 - accuracy: 0.7688 - val_loss: 0.4563 - val_accuracy: 0.8750\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.7344 - accuracy: 0.7969 - val_loss: 0.4082 - val_accuracy: 0.8750\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.7778 - accuracy: 0.7594 - val_loss: 0.4380 - val_accuracy: 0.9000\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 3s 286ms/step - loss: 0.7870 - accuracy: 0.7500 - val_loss: 0.4380 - val_accuracy: 0.9000\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.8563 - accuracy: 0.7344 - val_loss: 0.4951 - val_accuracy: 0.8750\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.7809 - accuracy: 0.7688 - val_loss: 0.4842 - val_accuracy: 0.9250\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.7169 - accuracy: 0.7906 - val_loss: 0.6579 - val_accuracy: 0.8250\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 2s 234ms/step - loss: 0.6715 - accuracy: 0.7906 - val_loss: 0.3450 - val_accuracy: 0.9250\n",
            "Epoch 102/150\n",
            "10/10 [==============================] - 3s 251ms/step - loss: 0.7217 - accuracy: 0.7875 - val_loss: 0.4394 - val_accuracy: 0.8500\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.7728 - accuracy: 0.7812 - val_loss: 0.3509 - val_accuracy: 0.9250\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.7385 - accuracy: 0.7781 - val_loss: 0.4270 - val_accuracy: 0.9250\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.7250 - accuracy: 0.7781 - val_loss: 0.3011 - val_accuracy: 0.9250\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 4s 423ms/step - loss: 0.6825 - accuracy: 0.8188 - val_loss: 0.3723 - val_accuracy: 0.9250\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 4s 346ms/step - loss: 0.6506 - accuracy: 0.7875 - val_loss: 0.3302 - val_accuracy: 0.9250\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.7021 - accuracy: 0.7906 - val_loss: 0.3151 - val_accuracy: 0.9500\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.5807 - accuracy: 0.8188 - val_loss: 0.3875 - val_accuracy: 0.9250\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 3s 282ms/step - loss: 0.7346 - accuracy: 0.7937 - val_loss: 0.4333 - val_accuracy: 0.9000\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5299 - accuracy: 0.8313 - val_loss: 0.3253 - val_accuracy: 0.9250\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.6046 - accuracy: 0.8000 - val_loss: 0.2625 - val_accuracy: 0.9500\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.6992 - accuracy: 0.7812 - val_loss: 0.3668 - val_accuracy: 0.8750\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.6353 - accuracy: 0.8000 - val_loss: 0.3476 - val_accuracy: 0.9250\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5642 - accuracy: 0.8188 - val_loss: 0.3473 - val_accuracy: 0.9250\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.6316 - accuracy: 0.7969 - val_loss: 0.3183 - val_accuracy: 0.9500\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.6403 - accuracy: 0.8094 - val_loss: 0.3454 - val_accuracy: 0.9000\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.6229 - accuracy: 0.8313 - val_loss: 0.3012 - val_accuracy: 0.9250\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 2s 247ms/step - loss: 0.6492 - accuracy: 0.7906 - val_loss: 0.4675 - val_accuracy: 0.8500\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 3s 254ms/step - loss: 0.5967 - accuracy: 0.8219 - val_loss: 0.3469 - val_accuracy: 0.9000\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.6236 - accuracy: 0.8000 - val_loss: 0.2907 - val_accuracy: 0.9250\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.6228 - accuracy: 0.8313 - val_loss: 0.2893 - val_accuracy: 0.9000\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5399 - accuracy: 0.8500 - val_loss: 0.3332 - val_accuracy: 0.9250\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.6123 - accuracy: 0.8000 - val_loss: 0.3354 - val_accuracy: 0.9750\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.6768 - accuracy: 0.7656 - val_loss: 0.3807 - val_accuracy: 0.9250\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5886 - accuracy: 0.8156 - val_loss: 0.2999 - val_accuracy: 0.9250\n",
            "Epoch 127/150\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.5984 - accuracy: 0.8156 - val_loss: 0.3848 - val_accuracy: 0.9000\n",
            "Epoch 128/150\n",
            "10/10 [==============================] - 3s 256ms/step - loss: 0.5853 - accuracy: 0.8000 - val_loss: 0.4734 - val_accuracy: 0.8750\n",
            "Epoch 129/150\n",
            "10/10 [==============================] - 2s 228ms/step - loss: 0.4945 - accuracy: 0.8500 - val_loss: 0.3851 - val_accuracy: 0.9000\n",
            "Epoch 130/150\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.5657 - accuracy: 0.8125 - val_loss: 0.4789 - val_accuracy: 0.8250\n",
            "Epoch 131/150\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.5804 - accuracy: 0.8281 - val_loss: 0.4505 - val_accuracy: 0.9000\n",
            "Epoch 132/150\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.5933 - accuracy: 0.8219 - val_loss: 0.4087 - val_accuracy: 0.9000\n",
            "Epoch 133/150\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.5667 - accuracy: 0.8125 - val_loss: 0.3258 - val_accuracy: 0.9000\n",
            "Epoch 134/150\n",
            "10/10 [==============================] - 3s 311ms/step - loss: 0.5920 - accuracy: 0.8250 - val_loss: 0.3283 - val_accuracy: 0.9250\n",
            "Epoch 135/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.6235 - accuracy: 0.7875 - val_loss: 0.4322 - val_accuracy: 0.9000\n",
            "Epoch 136/150\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.6625 - accuracy: 0.7875 - val_loss: 0.3214 - val_accuracy: 0.9500\n",
            "Epoch 137/150\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.6075 - accuracy: 0.8313 - val_loss: 0.3432 - val_accuracy: 0.9250\n",
            "Epoch 138/150\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.6431 - accuracy: 0.8125 - val_loss: 0.3679 - val_accuracy: 0.9250\n",
            "Epoch 139/150\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.5351 - accuracy: 0.8375 - val_loss: 0.3105 - val_accuracy: 0.9500\n",
            "Epoch 140/150\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5535 - accuracy: 0.8125 - val_loss: 0.3544 - val_accuracy: 0.9250\n",
            "Epoch 141/150\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4836 - accuracy: 0.8469 - val_loss: 0.2534 - val_accuracy: 0.9250\n",
            "Epoch 142/150\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.4953 - accuracy: 0.8562 - val_loss: 0.3052 - val_accuracy: 0.9000\n",
            "Epoch 143/150\n",
            "10/10 [==============================] - 3s 292ms/step - loss: 0.4731 - accuracy: 0.8469 - val_loss: 0.3870 - val_accuracy: 0.9250\n",
            "Epoch 144/150\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 0.5016 - accuracy: 0.8281 - val_loss: 0.3160 - val_accuracy: 0.9000\n",
            "Epoch 145/150\n",
            "10/10 [==============================] - 4s 414ms/step - loss: 0.4523 - accuracy: 0.8719 - val_loss: 0.2410 - val_accuracy: 0.9500\n",
            "Epoch 146/150\n",
            "10/10 [==============================] - 6s 624ms/step - loss: 0.4425 - accuracy: 0.8719 - val_loss: 0.2982 - val_accuracy: 0.9250\n",
            "Epoch 147/150\n",
            "10/10 [==============================] - 3s 308ms/step - loss: 0.4696 - accuracy: 0.8406 - val_loss: 0.2228 - val_accuracy: 0.9250\n",
            "Epoch 148/150\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.6287 - accuracy: 0.7844 - val_loss: 0.2579 - val_accuracy: 0.9500\n",
            "Epoch 149/150\n",
            "10/10 [==============================] - 3s 293ms/step - loss: 0.5349 - accuracy: 0.8313 - val_loss: 0.2868 - val_accuracy: 0.9250\n",
            "Epoch 150/150\n",
            "10/10 [==============================] - 5s 498ms/step - loss: 0.4257 - accuracy: 0.8562 - val_loss: 0.3830 - val_accuracy: 0.9000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5196 - accuracy: 0.8250\n",
            "Test Loss: 0.5196025967597961\n",
            "Test Accuracy: 0.824999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure the accuracy of the network on the validation and testing datasets **(P5-4: 5 points)**"
      ],
      "metadata": {
        "id": "PgZFoeHPPdqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(x_val, y_val)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "7VSZe8RdPkLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4202442-9daa-4a54-fecd-bd1c22e086ff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3830 - accuracy: 0.9000\n",
            "Validation Loss: 0.383034884929657\n",
            "Validation Accuracy: 0.8999999761581421\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5196 - accuracy: 0.8250\n",
            "Test Loss: 0.5196025967597961\n",
            "Test Accuracy: 0.824999988079071\n"
          ]
        }
      ]
    }
  ]
}